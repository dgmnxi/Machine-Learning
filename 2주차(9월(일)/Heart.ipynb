{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1I1oSyAuxgy6FEa34aISJBS2rSyP0Ffrf","authorship_tag":"ABX9TyOPcj1Vbo9hRpcrIN7hZao6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9vZMjS6PHFY","executionInfo":{"status":"ok","timestamp":1757383826885,"user_tz":-540,"elapsed":4512,"user":{"displayName":"얏호","userId":"01906474455130032815"}},"outputId":"a179e11d-a205-4e3c-fcd8-13d2748db498"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Test Accuracy ===\n","Decision Tree : 0.7049\n","Random Forest : 0.8197\n","Logistic Reg. : 0.8033\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.metrics import accuracy_score\n","\n","\n","\n","# -----------------------------\n","\n","# 1) 데이터 준비\n","\n","# -----------------------------\n","\n","col = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n","# Skip the first row when reading the CSV\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/heart.csv\", header=None, names=col, skiprows=[0]).dropna()\n","\n","\n","# feature이랑 label을 분리\n","X = df.drop(columns=[\"target\"])\n","y = df[\"target\"]\n","\n","\n","#train set, test set 분리 / stratify > y를 기준으로 셔플(뭉치지 않게)\n","X_train, X_test, y_train, y_test = train_test_split(\n","\n","    X, y, test_size=0.2, stratify=y, random_state=42\n","\n",")\n","\n","\n","\n","# -----------------------------\n","\n","# 2) 모델 구성\n","\n","# -----------------------------\n","\n","dt = DecisionTreeClassifier(random_state=42)\n","\n","rf = RandomForestClassifier(n_estimators=200, random_state=42)\n","\n","lr = LogisticRegression(max_iter=500)\n","\n","\n","\n","# -----------------------------\n","\n","# 3) 모델 학습\n","\n","# -----------------------------\n","\n","dt.fit(X_train, y_train)\n","\n","rf.fit(X_train, y_train)\n","\n","lr.fit(X_train, y_train)\n","\n","\n","\n","# -----------------------------\n","\n","# 4) 모델 평가\n","\n","# -----------------------------\n","\n","dt_acc = accuracy_score(y_test, dt.predict(X_test))\n","\n","rf_acc = accuracy_score(y_test, rf.predict(X_test))\n","\n","lr_acc = accuracy_score(y_test, lr.predict(X_test))\n","\n","\n","\n","print(\"=== Test Accuracy ===\")\n","\n","print(f\"Decision Tree : {dt_acc:.4f}\")\n","\n","print(f\"Random Forest : {rf_acc:.4f}\")\n","\n","print(f\"Logistic Reg. : {lr_acc:.4f}\")"]}]}